/home/taejoo/dsl_lab/Hi-Patch_taejoo/Hi-Patch/train_forecasting.py
2025-08-29 15:36:40
train_forecasting.py --dataset mimic --state def --history 24 --patience 10 --batch_size 8 --lr 1e-3 --patch_size 12 --stride 12 --nhead 1 --nlayer 1 --hid_dim 128 --seed 0 --gpu 0 --alpha 0.9
Namespace(state='def', n=100000000, epoch=1000, patience=10, history=24, pred_window=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=8, load=None, seed=0, dataset='mimic', quantization=0.0, model='Hi-Patch', nhead=1, nlayer=1, patch_size=12.0, stride=12.0, hid_dim=128, alpha=0.9, res=1, gpu='0', npatch=2, device=device(type='cuda', index=0), PID=1024983, ndim=96, patch_layer=2, scale_patch_size=0.25, task='forecasting')
- Epoch 000, ExpID 76698
Train - Loss (one batch): 0.00109
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01548, 0.01548, 0.12442, 0.07179, 95.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.01646, 0.01646, 0.12832, 0.07160, 107.29%
Time spent: 99.28s
- Epoch 001, ExpID 76698
Train - Loss (one batch): 0.00107
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01542, 0.01542, 0.12417, 0.06944, 99.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01636, 0.01636, 0.12793, 0.06908, 117.33%
Time spent: 99.22s
- Epoch 002, ExpID 76698
Train - Loss (one batch): 0.00491
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01566, 0.01566, 0.12514, 0.07438, 131.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01636, 0.01636, 0.12793, 0.06908, 117.33%
Time spent: 84.42s
- Epoch 003, ExpID 76698
Train - Loss (one batch): 0.01882
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01487, 0.01487, 0.12193, 0.06901, 124.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 99.06s
- Epoch 004, ExpID 76698
Train - Loss (one batch): 0.00114
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01587, 0.01587, 0.12596, 0.07070, 90.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.59s
- Epoch 005, ExpID 76698
Train - Loss (one batch): 0.00124
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01561, 0.01561, 0.12492, 0.07043, 91.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.41s
- Epoch 006, ExpID 76698
Train - Loss (one batch): 0.00853
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01514, 0.01514, 0.12306, 0.06963, 88.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.47s
- Epoch 007, ExpID 76698
Train - Loss (one batch): 0.00669
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01578, 0.01578, 0.12563, 0.07495, 119.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.56s
- Epoch 008, ExpID 76698
Train - Loss (one batch): 0.00285
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01535, 0.01535, 0.12390, 0.07039, 125.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.49s
- Epoch 009, ExpID 76698
Train - Loss (one batch): 0.00249
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01520, 0.01520, 0.12331, 0.07150, 106.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.43s
- Epoch 010, ExpID 76698
Train - Loss (one batch): 0.02398
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01514, 0.01514, 0.12303, 0.06995, 78.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.54s
- Epoch 011, ExpID 76698
Train - Loss (one batch): 0.00489
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01516, 0.01516, 0.12311, 0.06894, 97.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.44s
- Epoch 012, ExpID 76698
Train - Loss (one batch): 0.00168
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01520, 0.01520, 0.12328, 0.07326, 138.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.48s
- Epoch 013, ExpID 76698
Train - Loss (one batch): 0.00194
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01522, 0.01522, 0.12336, 0.06966, 103.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01627, 0.01627, 0.12754, 0.07023, 144.71%
Time spent: 84.50s
Avg Train Time per epoch: 70.03s
Avg Inference Time per epoch: 0.01996s
Avg Peak GPU Mem (Train): 11931.5 MB
Peak GPU Mem (Inference): 9294.4 MB
/home/taejoo/dsl_lab/Hi-Patch_taejoo/Hi-Patch/train_forecasting.py
2025-08-29 15:39:52
train_forecasting.py --dataset mimic --state def --history 24 --patience 10 --batch_size 8 --lr 1e-3 --patch_size 12 --stride 12 --nhead 1 --nlayer 1 --hid_dim 128 --seed 1 --gpu 0 --alpha 0.9
Namespace(state='def', n=100000000, epoch=1000, patience=10, history=24, pred_window=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=8, load=None, seed=1, dataset='mimic', quantization=0.0, model='Hi-Patch', nhead=1, nlayer=1, patch_size=12.0, stride=12.0, hid_dim=128, alpha=0.9, res=1, gpu='0', npatch=2, device=device(type='cuda', index=0), PID=1025099, ndim=96, patch_layer=2, scale_patch_size=0.25, task='forecasting')
- Epoch 000, ExpID 74317
Train - Loss (one batch): 0.00251
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01579, 0.01579, 0.12564, 0.07320, 118.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.01700, 0.01700, 0.13039, 0.07445, 136.94%
Time spent: 99.09s
- Epoch 001, ExpID 74317
Train - Loss (one batch): 0.00421
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01560, 0.01560, 0.12490, 0.07616, 116.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01667, 0.01667, 0.12913, 0.07706, 144.36%
Time spent: 98.89s
- Epoch 002, ExpID 74317
Train - Loss (one batch): 0.00071
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01521, 0.01521, 0.12333, 0.07385, 142.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01632, 0.01632, 0.12773, 0.07438, 160.10%
Time spent: 99.12s
- Epoch 003, ExpID 74317
Train - Loss (one batch): 0.00484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01521, 0.01521, 0.12332, 0.07131, 88.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01626, 0.01626, 0.12753, 0.07166, 112.62%
Time spent: 99.00s
- Epoch 004, ExpID 74317
Train - Loss (one batch): 0.00117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01486, 0.01486, 0.12189, 0.06952, 90.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.01605, 0.01605, 0.12668, 0.07020, 113.91%
Time spent: 98.88s
- Epoch 005, ExpID 74317
Train - Loss (one batch): 0.00173
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01522, 0.01522, 0.12335, 0.07344, 99.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.01605, 0.01605, 0.12668, 0.07020, 113.91%
Time spent: 84.15s
- Epoch 006, ExpID 74317
Train - Loss (one batch): 0.00065
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01484, 0.01484, 0.12183, 0.06838, 87.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 98.74s
- Epoch 007, ExpID 74317
Train - Loss (one batch): 0.00372
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01512, 0.01512, 0.12298, 0.06993, 105.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.36s
- Epoch 008, ExpID 74317
Train - Loss (one batch): 0.01199
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01537, 0.01537, 0.12397, 0.07481, 113.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.43s
- Epoch 009, ExpID 74317
Train - Loss (one batch): 0.00078
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01486, 0.01486, 0.12190, 0.06870, 84.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.32s
- Epoch 010, ExpID 74317
Train - Loss (one batch): 0.00605
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01511, 0.01511, 0.12292, 0.06960, 112.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.32s
- Epoch 011, ExpID 74317
Train - Loss (one batch): 0.01570
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01552, 0.01552, 0.12457, 0.07253, 104.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.46s
- Epoch 012, ExpID 74317
Train - Loss (one batch): 0.00141
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01512, 0.01512, 0.12296, 0.07047, 111.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.42s
- Epoch 013, ExpID 74317
Train - Loss (one batch): 0.00060
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01524, 0.01524, 0.12346, 0.06945, 112.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.39s
- Epoch 014, ExpID 74317
Train - Loss (one batch): 0.00458
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01505, 0.01505, 0.12269, 0.06962, 87.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.33s
- Epoch 015, ExpID 74317
Train - Loss (one batch): 0.00843
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01508, 0.01508, 0.12279, 0.07072, 100.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.17s
- Epoch 016, ExpID 74317
Train - Loss (one batch): 0.00833
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01506, 0.01506, 0.12273, 0.06915, 88.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01596, 0.01596, 0.12633, 0.06893, 114.57%
Time spent: 84.29s
Avg Train Time per epoch: 69.90s
Avg Inference Time per epoch: 0.01993s
Avg Peak GPU Mem (Train): 11943.2 MB
Peak GPU Mem (Inference): 9294.4 MB
/home/taejoo/dsl_lab/Hi-Patch_taejoo/Hi-Patch/train_forecasting.py
2025-08-29 15:58:14
train_forecasting.py --dataset mimic --state def --history 24 --patience 10 --batch_size 8 --lr 1e-3 --patch_size 12 --stride 12 --nhead 1 --nlayer 1 --hid_dim 128 --seed 2 --gpu 0 --alpha 0.9
Namespace(state='def', n=100000000, epoch=1000, patience=10, history=24, pred_window=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=8, load=None, seed=2, dataset='mimic', quantization=0.0, model='Hi-Patch', nhead=1, nlayer=1, patch_size=12.0, stride=12.0, hid_dim=128, alpha=0.9, res=1, gpu='0', npatch=2, device=device(type='cuda', index=0), PID=1025537, ndim=96, patch_layer=2, scale_patch_size=0.25, task='forecasting')
- Epoch 000, ExpID 91988
Train - Loss (one batch): 0.00157
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01568, 0.01568, 0.12524, 0.07423, 127.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.01674, 0.01674, 0.12939, 0.07519, 148.75%
Time spent: 100.14s
- Epoch 001, ExpID 91988
Train - Loss (one batch): 0.00303
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01528, 0.01528, 0.12362, 0.07030, 115.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01613, 0.01613, 0.12699, 0.07107, 130.74%
Time spent: 99.12s
- Epoch 002, ExpID 91988
Train - Loss (one batch): 0.00405
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01571, 0.01571, 0.12534, 0.07028, 88.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01613, 0.01613, 0.12699, 0.07107, 130.74%
Time spent: 84.41s
- Epoch 003, ExpID 91988
Train - Loss (one batch): 0.00285
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01507, 0.01507, 0.12275, 0.06947, 92.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01613, 0.01613, 0.12701, 0.06999, 114.32%
Time spent: 99.02s
- Epoch 004, ExpID 91988
Train - Loss (one batch): 0.01388
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01573, 0.01573, 0.12542, 0.07198, 89.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01613, 0.01613, 0.12701, 0.06999, 114.32%
Time spent: 84.48s
- Epoch 005, ExpID 91988
Train - Loss (one batch): 0.00361
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01524, 0.01524, 0.12345, 0.07253, 137.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01613, 0.01613, 0.12701, 0.06999, 114.32%
Time spent: 84.44s
- Epoch 006, ExpID 91988
Train - Loss (one batch): 0.01171
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01490, 0.01490, 0.12206, 0.07060, 90.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 98.93s
- Epoch 007, ExpID 91988
Train - Loss (one batch): 0.00535
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01527, 0.01527, 0.12359, 0.07137, 95.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.50s
- Epoch 008, ExpID 91988
Train - Loss (one batch): 0.00309
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01497, 0.01497, 0.12234, 0.07094, 103.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.56s
- Epoch 009, ExpID 91988
Train - Loss (one batch): 0.02439
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01498, 0.01498, 0.12238, 0.06949, 103.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.41s
- Epoch 010, ExpID 91988
Train - Loss (one batch): 0.00789
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01531, 0.01531, 0.12373, 0.07130, 125.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.56s
- Epoch 011, ExpID 91988
Train - Loss (one batch): 0.00445
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01538, 0.01538, 0.12403, 0.06939, 92.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.46s
- Epoch 012, ExpID 91988
Train - Loss (one batch): 0.00246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01514, 0.01514, 0.12305, 0.06839, 98.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.47s
- Epoch 013, ExpID 91988
Train - Loss (one batch): nan
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01546, 0.01546, 0.12433, 0.07334, 118.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.51s
- Epoch 014, ExpID 91988
Train - Loss (one batch): 0.00102
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01571, 0.01571, 0.12533, 0.06912, 84.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.48s
- Epoch 015, ExpID 91988
Train - Loss (one batch): 0.02474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01577, 0.01577, 0.12557, 0.07153, 89.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.36s
- Epoch 016, ExpID 91988
Train - Loss (one batch): 0.00539
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01577, 0.01577, 0.12559, 0.06898, 93.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01593, 0.01593, 0.12620, 0.07117, 110.26%
Time spent: 84.45s
Avg Train Time per epoch: 70.03s
Avg Inference Time per epoch: 0.01991s
Avg Peak GPU Mem (Train): 11930.5 MB
Peak GPU Mem (Inference): 9294.4 MB
/home/taejoo/dsl_lab/Hi-Patch_taejoo/Hi-Patch/train_forecasting.py
2025-08-29 16:06:17
train_forecasting.py --dataset mimic --state def --history 24 --patience 10 --batch_size 8 --lr 1e-3 --patch_size 12 --stride 12 --nhead 1 --nlayer 1 --hid_dim 128 --seed 3 --gpu 0 --alpha 0.9
Namespace(state='def', n=100000000, epoch=1000, patience=10, history=24, pred_window=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=8, load=None, seed=3, dataset='mimic', quantization=0.0, model='Hi-Patch', nhead=1, nlayer=1, patch_size=12.0, stride=12.0, hid_dim=128, alpha=0.9, res=1, gpu='0', npatch=2, device=device(type='cuda', index=0), PID=1025691, ndim=96, patch_layer=2, scale_patch_size=0.25, task='forecasting')
- Epoch 000, ExpID 5059
Train - Loss (one batch): 0.00424
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01592, 0.01592, 0.12616, 0.07440, 120.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.01657, 0.01657, 0.12873, 0.07483, 130.42%
Time spent: 99.94s
- Epoch 001, ExpID 5059
Train - Loss (one batch): 0.00332
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01542, 0.01542, 0.12419, 0.07055, 90.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01644, 0.01644, 0.12824, 0.07082, 102.82%
Time spent: 98.97s
- Epoch 002, ExpID 5059
Train - Loss (one batch): 0.02580
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01584, 0.01584, 0.12587, 0.07402, 90.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01644, 0.01644, 0.12824, 0.07082, 102.82%
Time spent: 84.31s
- Epoch 003, ExpID 5059
Train - Loss (one batch): 0.00351
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01524, 0.01524, 0.12344, 0.07067, 105.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01632, 0.01632, 0.12774, 0.07149, 126.86%
Time spent: 99.06s
- Epoch 004, ExpID 5059
Train - Loss (one batch): 0.01650
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01516, 0.01516, 0.12311, 0.07108, 100.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.01645, 0.01645, 0.12826, 0.07169, 122.67%
Time spent: 98.79s
- Epoch 005, ExpID 5059
Train - Loss (one batch): 0.00384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01522, 0.01522, 0.12338, 0.07116, 103.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.01645, 0.01645, 0.12826, 0.07169, 122.67%
Time spent: 84.46s
- Epoch 006, ExpID 5059
Train - Loss (one batch): 0.01038
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01550, 0.01550, 0.12449, 0.07108, 93.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.01645, 0.01645, 0.12826, 0.07169, 122.67%
Time spent: 84.36s
- Epoch 007, ExpID 5059
Train - Loss (one batch): 0.02382
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01517, 0.01517, 0.12315, 0.06986, 92.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.01645, 0.01645, 0.12826, 0.07169, 122.67%
Time spent: 84.57s
- Epoch 008, ExpID 5059
Train - Loss (one batch): 0.00928
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01504, 0.01504, 0.12263, 0.06843, 96.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.01617, 0.01617, 0.12716, 0.06915, 122.84%
Time spent: 99.05s
- Epoch 009, ExpID 5059
Train - Loss (one batch): 0.00064
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01493, 0.01493, 0.12217, 0.06856, 87.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 99.11s
- Epoch 010, ExpID 5059
Train - Loss (one batch): 0.00306
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01507, 0.01507, 0.12275, 0.06953, 94.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.55s
- Epoch 011, ExpID 5059
Train - Loss (one batch): 0.00812
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01532, 0.01532, 0.12378, 0.06999, 106.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.42s
- Epoch 012, ExpID 5059
Train - Loss (one batch): 0.00493
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01578, 0.01578, 0.12561, 0.07571, 103.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.37s
- Epoch 013, ExpID 5059
Train - Loss (one batch): 0.00644
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01555, 0.01555, 0.12472, 0.06931, 89.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.36s
- Epoch 014, ExpID 5059
Train - Loss (one batch): 0.01526
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01533, 0.01533, 0.12382, 0.07041, 102.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.52s
- Epoch 015, ExpID 5059
Train - Loss (one batch): 0.00080
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01519, 0.01519, 0.12324, 0.06952, 113.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.45s
- Epoch 016, ExpID 5059
Train - Loss (one batch): 0.00665
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01590, 0.01590, 0.12610, 0.07413, 143.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.43s
- Epoch 017, ExpID 5059
Train - Loss (one batch): 0.00783
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01534, 0.01534, 0.12384, 0.06989, 102.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.59s
- Epoch 018, ExpID 5059
Train - Loss (one batch): 0.00464
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01534, 0.01534, 0.12384, 0.06880, 103.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.29s
- Epoch 019, ExpID 5059
Train - Loss (one batch): 0.01683
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01540, 0.01540, 0.12410, 0.07073, 98.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01578, 0.01578, 0.12564, 0.06849, 110.50%
Time spent: 84.47s
Avg Train Time per epoch: 69.96s
Avg Inference Time per epoch: 0.01996s
Avg Peak GPU Mem (Train): 11930.6 MB
Peak GPU Mem (Inference): 9294.3 MB
/home/taejoo/dsl_lab/Hi-Patch_taejoo/Hi-Patch/train_forecasting.py
2025-08-29 16:24:16
train_forecasting.py --dataset mimic --state def --history 24 --patience 10 --batch_size 8 --lr 1e-3 --patch_size 12 --stride 12 --nhead 1 --nlayer 1 --hid_dim 128 --seed 4 --gpu 0 --alpha 0.9
Namespace(state='def', n=100000000, epoch=1000, patience=10, history=24, pred_window=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=8, load=None, seed=4, dataset='mimic', quantization=0.0, model='Hi-Patch', nhead=1, nlayer=1, patch_size=12.0, stride=12.0, hid_dim=128, alpha=0.9, res=1, gpu='0', npatch=2, device=device(type='cuda', index=0), PID=1025925, ndim=96, patch_layer=2, scale_patch_size=0.25, task='forecasting')
- Epoch 000, ExpID 59155
Train - Loss (one batch): 0.00183
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01593, 0.01593, 0.12621, 0.07468, 125.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.01682, 0.01682, 0.12971, 0.07544, 138.29%
Time spent: 99.82s
- Epoch 001, ExpID 59155
Train - Loss (one batch): 0.00193
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01566, 0.01566, 0.12513, 0.07379, 104.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01669, 0.01669, 0.12921, 0.07391, 116.99%
Time spent: 99.18s
- Epoch 002, ExpID 59155
Train - Loss (one batch): 0.00124
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01519, 0.01519, 0.12324, 0.06998, 117.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01600, 0.01600, 0.12647, 0.07027, 127.44%
Time spent: 99.10s
- Epoch 003, ExpID 59155
Train - Loss (one batch): 0.00949
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01527, 0.01527, 0.12356, 0.07472, 145.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01600, 0.01600, 0.12647, 0.07027, 127.44%
Time spent: 84.63s
- Epoch 004, ExpID 59155
Train - Loss (one batch): 0.00413
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01558, 0.01558, 0.12483, 0.07348, 117.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01600, 0.01600, 0.12647, 0.07027, 127.44%
Time spent: 84.68s
- Epoch 005, ExpID 59155
Train - Loss (one batch): 0.02090
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01534, 0.01534, 0.12385, 0.07070, 114.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01600, 0.01600, 0.12647, 0.07027, 127.44%
Time spent: 84.55s
- Epoch 006, ExpID 59155
Train - Loss (one batch): 0.00134
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01546, 0.01546, 0.12434, 0.07255, 107.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01600, 0.01600, 0.12647, 0.07027, 127.44%
Time spent: 84.60s
- Epoch 007, ExpID 59155
Train - Loss (one batch): 0.00372
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01533, 0.01533, 0.12380, 0.07141, 108.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01600, 0.01600, 0.12647, 0.07027, 127.44%
Time spent: 84.52s
- Epoch 008, ExpID 59155
Train - Loss (one batch): 0.00255
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01539, 0.01539, 0.12405, 0.07050, 99.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01600, 0.01600, 0.12647, 0.07027, 127.44%
Time spent: 84.35s
- Epoch 009, ExpID 59155
Train - Loss (one batch): 0.00262
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01507, 0.01507, 0.12278, 0.07009, 120.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01607, 0.01607, 0.12677, 0.07002, 128.35%
Time spent: 99.23s
- Epoch 010, ExpID 59155
Train - Loss (one batch): 0.00747
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01505, 0.01505, 0.12267, 0.07020, 111.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.01578, 0.01578, 0.12563, 0.07024, 118.73%
Time spent: 99.22s
- Epoch 011, ExpID 59155
Train - Loss (one batch): 0.00388
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01528, 0.01528, 0.12359, 0.06857, 118.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.01578, 0.01578, 0.12563, 0.07024, 118.73%
Time spent: 84.58s
- Epoch 012, ExpID 59155
Train - Loss (one batch): 0.00122
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01488, 0.01488, 0.12198, 0.06828, 114.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.01591, 0.01591, 0.12614, 0.06825, 124.16%
Time spent: 98.91s
- Epoch 013, ExpID 59155
Train - Loss (one batch): 0.00208
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01522, 0.01522, 0.12337, 0.07428, 140.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.01591, 0.01591, 0.12614, 0.06825, 124.16%
Time spent: 84.30s
- Epoch 014, ExpID 59155
Train - Loss (one batch): 0.01605
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01544, 0.01544, 0.12426, 0.07139, 104.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.01591, 0.01591, 0.12614, 0.06825, 124.16%
Time spent: 84.28s
- Epoch 015, ExpID 59155
Train - Loss (one batch): 0.00037
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01501, 0.01501, 0.12253, 0.06859, 109.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.01591, 0.01591, 0.12614, 0.06825, 124.16%
Time spent: 84.63s
- Epoch 016, ExpID 59155
Train - Loss (one batch): 0.00063
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01487, 0.01487, 0.12195, 0.06955, 110.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 99.10s
- Epoch 017, ExpID 59155
Train - Loss (one batch): 0.00377
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01495, 0.01495, 0.12226, 0.06900, 103.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.37s
- Epoch 018, ExpID 59155
Train - Loss (one batch): 0.00203
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01502, 0.01502, 0.12254, 0.06915, 102.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.56s
- Epoch 019, ExpID 59155
Train - Loss (one batch): 0.00763
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01519, 0.01519, 0.12325, 0.07166, 117.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.57s
- Epoch 020, ExpID 59155
Train - Loss (one batch): 0.03431
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01489, 0.01489, 0.12203, 0.06812, 102.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.53s
- Epoch 021, ExpID 59155
Train - Loss (one batch): 0.00603
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01498, 0.01498, 0.12241, 0.06754, 104.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.43s
- Epoch 022, ExpID 59155
Train - Loss (one batch): 0.00481
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01497, 0.01497, 0.12237, 0.06855, 96.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.43s
- Epoch 023, ExpID 59155
Train - Loss (one batch): 0.00846
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01523, 0.01523, 0.12340, 0.06951, 100.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.62s
- Epoch 024, ExpID 59155
Train - Loss (one batch): 0.00453
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01517, 0.01517, 0.12317, 0.06898, 94.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.53s
- Epoch 025, ExpID 59155
Train - Loss (one batch): 0.01886
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01506, 0.01506, 0.12273, 0.06976, 97.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.47s
- Epoch 026, ExpID 59155
Train - Loss (one batch): 0.00285
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01504, 0.01504, 0.12264, 0.06925, 95.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01608, 0.01608, 0.12679, 0.07001, 124.61%
Time spent: 84.59s
Avg Train Time per epoch: 70.09s
Avg Inference Time per epoch: 0.01995s
Avg Peak GPU Mem (Train): 11940.3 MB
Peak GPU Mem (Inference): 9294.4 MB
