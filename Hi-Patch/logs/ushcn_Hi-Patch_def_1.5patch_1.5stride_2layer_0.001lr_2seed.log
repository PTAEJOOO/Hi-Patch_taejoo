/home/taejoo/dsl_lab/Hi-Patch_taejoo/Hi-Patch/train_forecasting.py
2025-08-29 14:12:34
train_forecasting.py --dataset ushcn --state def --history 24 --pred_window 1 --patience 10 --batch_size 192 --lr 1e-3 --patch_size 1.5 --stride 1.5 --nhead 4 --nlayer 2 --hid_dim 64 --seed 2 --gpu 0 --alpha 1
Namespace(state='def', n=100000000, epoch=1000, patience=10, history=24, pred_window=1, logmode='a', lr=0.001, w_decay=0.0, batch_size=192, load=None, seed=2, dataset='ushcn', quantization=0.0, model='Hi-Patch', nhead=4, nlayer=2, patch_size=1.5, stride=1.5, hid_dim=64, alpha=1.0, res=1, gpu='0', npatch=16, device=device(type='cuda', index=0), PID=1020396, n_months=48, ndim=5, patch_layer=5, scale_patch_size=0.06, task='forecasting')
- Epoch 000, ExpID 19786
Train - Loss (one batch): 0.74107
Val - Loss, MSE, RMSE, MAE, MAPE: 0.85617, 0.85617, 0.92529, 0.40950, -69.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.63863, 0.63863, 0.79914, 0.38351, -62.37%
Time spent: 47.48s
- Epoch 001, ExpID 19786
Train - Loss (one batch): 0.56498
Val - Loss, MSE, RMSE, MAE, MAPE: 0.73506, 0.73506, 0.85736, 0.34461, -57.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.53095, 0.53095, 0.72866, 0.31892, -52.72%
Time spent: 47.09s
- Epoch 002, ExpID 19786
Train - Loss (one batch): 0.41070
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69259, 0.69259, 0.83222, 0.33822, -58.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.51159, 0.51159, 0.71525, 0.31328, -53.12%
Time spent: 47.06s
- Epoch 003, ExpID 19786
Train - Loss (one batch): 0.55687
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70180, 0.70180, 0.83773, 0.37678, -83.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.51159, 0.51159, 0.71525, 0.31328, -53.12%
Time spent: 40.70s
- Epoch 004, ExpID 19786
Train - Loss (one batch): 0.37240
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67343, 0.67343, 0.82063, 0.33295, -59.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.50640, 0.50640, 0.71162, 0.30538, -53.16%
Time spent: 47.08s
- Epoch 005, ExpID 19786
Train - Loss (one batch): 0.51484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65952, 0.65952, 0.81211, 0.33325, -57.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.50111, 0.50111, 0.70789, 0.30676, -51.22%
Time spent: 47.04s
- Epoch 006, ExpID 19786
Train - Loss (one batch): 0.38945
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66238, 0.66238, 0.81386, 0.33408, -56.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.50111, 0.50111, 0.70789, 0.30676, -51.22%
Time spent: 40.65s
- Epoch 007, ExpID 19786
Train - Loss (one batch): 0.58561
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66159, 0.66159, 0.81338, 0.31915, -50.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.50111, 0.50111, 0.70789, 0.30676, -51.22%
Time spent: 40.72s
- Epoch 008, ExpID 19786
Train - Loss (one batch): 0.55681
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63941, 0.63941, 0.79963, 0.32151, -54.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.49456, 0.49456, 0.70325, 0.29564, -48.70%
Time spent: 47.20s
- Epoch 009, ExpID 19786
Train - Loss (one batch): 1.10807
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67270, 0.67270, 0.82018, 0.34648, -68.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.49456, 0.49456, 0.70325, 0.29564, -48.70%
Time spent: 40.64s
- Epoch 010, ExpID 19786
Train - Loss (one batch): 0.38036
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63743, 0.63743, 0.79839, 0.34948, -70.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 47.03s
- Epoch 011, ExpID 19786
Train - Loss (one batch): 0.64664
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65739, 0.65739, 0.81080, 0.35217, -71.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.66s
- Epoch 012, ExpID 19786
Train - Loss (one batch): 1.58313
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64018, 0.64018, 0.80012, 0.34926, -68.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.66s
- Epoch 013, ExpID 19786
Train - Loss (one batch): 0.29311
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64934, 0.64934, 0.80581, 0.33997, -65.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.69s
- Epoch 014, ExpID 19786
Train - Loss (one batch): 0.14642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65276, 0.65276, 0.80794, 0.33486, -61.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.65s
- Epoch 015, ExpID 19786
Train - Loss (one batch): 0.63083
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66131, 0.66131, 0.81321, 0.33614, -61.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.70s
- Epoch 016, ExpID 19786
Train - Loss (one batch): 0.41939
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64356, 0.64356, 0.80222, 0.31331, -40.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.69s
- Epoch 017, ExpID 19786
Train - Loss (one batch): 0.57886
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65315, 0.65315, 0.80818, 0.33842, -60.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.71s
- Epoch 018, ExpID 19786
Train - Loss (one batch): 0.31851
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68133, 0.68133, 0.82543, 0.33073, -54.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.67s
- Epoch 019, ExpID 19786
Train - Loss (one batch): 0.42196
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66274, 0.66274, 0.81409, 0.32682, -57.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.72s
- Epoch 020, ExpID 19786
Train - Loss (one batch): 0.43127
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64637, 0.64637, 0.80397, 0.32102, -53.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.49392, 0.49392, 0.70279, 0.32367, -63.55%
Time spent: 40.66s
Avg Train Time per epoch: 34.34s
Avg Inference Time per epoch: 0.17929s
Avg Peak GPU Mem (Train): 3721.9 MB
Peak GPU Mem (Inference): 2927.5 MB
